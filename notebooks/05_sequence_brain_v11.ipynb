{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm2WOg5bLJbG",
        "outputId": "641fd4ff-8c74-4b58-902c-6cf8e9f286d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cpu (Sequence Brain v11)\n",
            "Всего строк: 13113\n",
            "Колонок: 201\n",
            "Первые колонки: ['transdatetime', 'cst_dim_id', 'transdate', 'amount', 'docno', 'direction', 'target', 'row_id', 'sess_monthly_os_changes', 'sess_monthly_phone_model_changes', 'sess_logins_7d', 'sess_logins_30d', 'sess_login_freq_7d', 'sess_login_freq_30d', 'sess_freq_change_7d_vs_mean', 'sess_logins_7d_30d_ratio', 'sess_avg_login_interval_30d', 'sess_std_login_interval_30d', 'sess_var_login_interval_30d', 'sess_ewm_login_interval_7d', 'sess_burstiness_login_interval', 'sess_fano_login_interval', 'sess_z_login_interval_7d', 'sess_has_login_history', 'sess_last_phone_model'] ...\n",
            "\n",
            "Распределение target:\n",
            "target\n",
            "0    12948\n",
            "1      165\n",
            "Name: count, dtype: int64\n",
            "Доля фрода: 0.012582932967284374\n",
            "\n",
            "Загружены AE-фичи из config/autoencoder_features_v11.json\n",
            "\n",
            "Финальные event-фичи для Sequence AE v11: 56\n",
            "['amount', 'cst_fraud_share', 'dayofweek', 'decimal_depth', 'degree_cst', 'degree_dir', 'dir_fraud_share', 'dir_tx_60m', 'dir_unique_senders_60m', 'dow_cos', 'dow_sin', 'hour', 'hour_cos', 'hour_sin', 'is_weekend', 'log_amount', 'many_to_one_flag', 'one_to_many_flag', 'risk_fast_oof_v11', 'sess_avg_login_interval_30d', 'sess_burstiness_login_interval', 'sess_ewm_login_interval_7d', 'sess_fano_login_interval', 'sess_freq_change_7d_vs_mean', 'sess_has_login_history', 'sess_login_freq_30d', 'sess_login_freq_7d', 'sess_logins_30d', 'sess_logins_7d', 'sess_logins_7d_30d_ratio', 'sess_monthly_os_changes', 'sess_monthly_phone_model_changes', 'sess_std_login_interval_30d', 'sess_var_login_interval_30d', 'sess_z_login_interval_7d', 'user_max_amount_30d', 'user_max_amount_7d', 'user_max_amount_90d', 'user_mean_amount_30d', 'user_mean_amount_7d', 'user_mean_amount_90d', 'user_min_amount_30d', 'user_min_amount_7d', 'user_min_amount_90d', 'user_new_dirs_60m', 'user_std_amount_30d', 'user_std_amount_7d', 'user_std_amount_90d', 'user_sum_60m', 'user_tx_10m', 'user_tx_1m', 'user_tx_60m', 'user_tx_count_30d', 'user_tx_count_7d', 'user_tx_count_90d', 'z_amount_30d']\n",
            "\n",
            "После сортировки по клиенту и времени, строк: 13113\n",
            "MAX_SEQ_LEN=30\n",
            "Доля транзакций с непустой историей: 0.9732326698695951\n",
            "\n",
            "Нормальных транзакций с историей: 12612\n",
            "Train normal size: 11350\n",
            "Val normal size: 1262\n",
            "\n",
            "Скейлер Sequence AE сохранён в models/seq_scaler_v11.pkl\n",
            "Input dim Sequence AE: 56\n",
            "\n",
            "================= Обучение Sequence Autoencoder v11 =================\n",
            "Epoch 001 | train_loss=0.867294 | val_loss=1.025471\n",
            "Epoch 002 | train_loss=0.698462 | val_loss=0.950365\n",
            "Epoch 003 | train_loss=0.646907 | val_loss=0.921570\n",
            "Epoch 004 | train_loss=0.610824 | val_loss=0.902048\n",
            "Epoch 005 | train_loss=0.584375 | val_loss=0.891143\n",
            "Epoch 006 | train_loss=0.569208 | val_loss=0.882151\n",
            "Epoch 007 | train_loss=0.557502 | val_loss=0.880733\n",
            "Epoch 008 | train_loss=0.547459 | val_loss=0.875950\n",
            "Epoch 009 | train_loss=0.541278 | val_loss=0.871092\n",
            "Epoch 010 | train_loss=0.536344 | val_loss=0.868535\n",
            "Epoch 011 | train_loss=0.525367 | val_loss=0.864674\n",
            "Epoch 012 | train_loss=0.517862 | val_loss=0.860545\n",
            "Epoch 013 | train_loss=0.511693 | val_loss=0.861857\n",
            "Epoch 014 | train_loss=0.505488 | val_loss=0.859493\n",
            "Epoch 015 | train_loss=0.505051 | val_loss=0.854367\n",
            "Epoch 016 | train_loss=0.500678 | val_loss=0.855153\n",
            "Epoch 017 | train_loss=0.494972 | val_loss=0.850987\n",
            "Epoch 018 | train_loss=0.490912 | val_loss=0.848551\n",
            "Epoch 019 | train_loss=0.483727 | val_loss=0.851841\n",
            "Epoch 020 | train_loss=0.481023 | val_loss=0.848149\n",
            "Epoch 021 | train_loss=0.478807 | val_loss=0.848089\n",
            "Epoch 022 | train_loss=0.476759 | val_loss=0.848022\n",
            "Epoch 023 | train_loss=0.469499 | val_loss=0.849891\n",
            "Epoch 024 | train_loss=0.464199 | val_loss=0.846702\n",
            "Epoch 025 | train_loss=0.460559 | val_loss=0.849448\n",
            "Epoch 026 | train_loss=0.457215 | val_loss=0.849298\n",
            "Epoch 027 | train_loss=0.451811 | val_loss=0.849736\n",
            "Epoch 028 | train_loss=0.449547 | val_loss=0.852687\n",
            "Epoch 029 | train_loss=0.446889 | val_loss=0.850858\n",
            "Epoch 030 | train_loss=0.445880 | val_loss=0.851986\n",
            "Epoch 031 | train_loss=0.437962 | val_loss=0.853070\n",
            "Epoch 032 | train_loss=0.433812 | val_loss=0.850947\n",
            "Early stopping на эпохе 32, best_epoch=24, best_val_loss=0.846702\n",
            "Загружено лучшее состояние модели Sequence AE (epoch=24)\n",
            "\n",
            "Sequence AE (reconstruction error) по нормальным:\n",
            "  mu_log: 0.2935514748096466\n",
            "  sigma_log: 0.2870275378227234\n",
            "\n",
            "Per-feature Sequence AE MSE сохранён в data/processed/sequence_autoencoder_feature_importance_v11.parquet\n",
            "                       feature        mse\n",
            "0              dir_fraud_share  56.728531\n",
            "1                   degree_dir   1.147889\n",
            "2            risk_fast_oof_v11   1.138058\n",
            "3             many_to_one_flag   1.036257\n",
            "4                   user_tx_1m   0.976397\n",
            "5                     hour_cos   0.968457\n",
            "6                     hour_sin   0.964300\n",
            "7                         hour   0.961489\n",
            "8                 z_amount_30d   0.914361\n",
            "9       dir_unique_senders_60m   0.894640\n",
            "10               decimal_depth   0.868806\n",
            "11  sess_ewm_login_interval_7d   0.795236\n",
            "12                 user_tx_10m   0.782982\n",
            "13                   dayofweek   0.766161\n",
            "14                  is_weekend   0.755486\n",
            "15                  dir_tx_60m   0.747340\n",
            "16                     dow_cos   0.738136\n",
            "17                  log_amount   0.735846\n",
            "18                     dow_sin   0.715926\n",
            "19                      amount   0.710967\n",
            "\n",
            "=== Метрики Sequence AE (по лог-ошибке) ===\n",
            "ROC-AUC (Seq AE): 0.8040951685529998\n",
            "PR-AUC  (Seq AE): 0.21637166595007054\n",
            "Baseline PR-AUC (random): 0.012582932967284374\n",
            "\n",
            "Размер X_seq_meta: (13113, 29)\n",
            "seq_meta_features: ['seq_log_recon_error_v11', 'seq_z_recon_error_v11', 'seq_hist_len_v11', 'ae_log_recon_error_v11', 'ae_z_recon_error_v11', 'log_amount', 'z_amount_30d', 'user_tx_1m', 'user_tx_10m', 'user_tx_60m', 'user_sum_60m', 'user_tx_count_7d', 'user_tx_count_30d', 'user_tx_count_90d', 'user_mean_amount_7d', 'user_mean_amount_30d', 'user_std_amount_7d', 'user_std_amount_30d', 'degree_cst', 'degree_dir', 'cst_fraud_share', 'dir_fraud_share', 'sess_logins_7d', 'sess_logins_30d', 'sess_logins_7d_30d_ratio', 'sess_login_freq_7d', 'sess_login_freq_30d', 'sess_burstiness_login_interval', 'sess_z_login_interval_7d']\n",
            "Список фич sequence meta-модели сохранён в config/sequence_meta_features_v11.json\n",
            "\n",
            "================ OOF-обучение risk_seq (LogisticRegression) ================\n",
            "  Fold 1/5 ROC-AUC=0.8991, PR-AUC=0.3389\n",
            "  Fold 2/5 ROC-AUC=0.9053, PR-AUC=0.4635\n",
            "  Fold 3/5 ROC-AUC=0.9067, PR-AUC=0.3584\n",
            "  Fold 4/5 ROC-AUC=0.9472, PR-AUC=0.4200\n",
            "  Fold 5/5 ROC-AUC=0.8996, PR-AUC=0.4798\n",
            "\n",
            "=== CV по фолдам для risk_seq ===\n",
            "  Fold 1: ROC-AUC=0.8991, PR-AUC=0.3389\n",
            "  Fold 2: ROC-AUC=0.9053, PR-AUC=0.4635\n",
            "  Fold 3: ROC-AUC=0.9067, PR-AUC=0.3584\n",
            "  Fold 4: ROC-AUC=0.9472, PR-AUC=0.4200\n",
            "  Fold 5: ROC-AUC=0.8996, PR-AUC=0.4798\n",
            "OOF ROC-AUC: 0.9103\n",
            "OOF PR-AUC : 0.4072\n",
            "OOF Baseline PR-AUC (random): 0.012582932967284374\n",
            "\n",
            "Пример метрик по порогам (первые 10 строк):\n",
            "      threshold  precision  recall        f1\n",
            "0  2.051837e-30   0.012583     1.0  0.024853\n",
            "1  9.731829e-10   0.012625     1.0  0.024936\n",
            "2  1.587625e-07   0.012668     1.0  0.025019\n",
            "3  1.203965e-06   0.012711     1.0  0.025103\n",
            "4  5.164625e-06   0.012754     1.0  0.025187\n",
            "5  1.078403e-05   0.012798     1.0  0.025272\n",
            "6  2.206966e-05   0.012841     1.0  0.025357\n",
            "7  3.988356e-05   0.012885     1.0  0.025441\n",
            "8  6.549064e-05   0.012929     1.0  0.025528\n",
            "9  1.029385e-04   0.012974     1.0  0.025615\n",
            "\n",
            "=== Пороги стратегий по OOF для risk_seq v11 ===\n",
            "Aggressive: threshold=0.272, precision=0.039, recall=0.903, f1=0.075\n",
            "Balanced: threshold=0.985, precision=0.614, recall=0.327, f1=0.427\n",
            "Friendly: threshold=1.000, precision=0.977, recall=0.261, f1=0.411\n",
            "\n",
            "Мета-модель risk_seq v11 сохранена в models/seq_meta_v11.pkl\n",
            "Пороги risk_seq v11 сохранены в config/sequence_thresholds_v11.json\n",
            "Sequence AE модель сохранена в models/seq_autoencoder_v11.pt\n",
            "\n",
            "✅ Обновлённый feature store с Sequence Brain v11 сохранён в data/processed/features_offline_v11.parquet\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.base import clone\n",
        "import joblib\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ===========================\n",
        "#  Config & paths\n",
        "# ===========================\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"DEVICE: {DEVICE} (Sequence Brain v11)\")\n",
        "\n",
        "DATA_DIR = Path(\"data\") / \"processed\"\n",
        "MODELS_DIR = Path(\"models\")\n",
        "CONFIG_DIR = Path(\"config\")\n",
        "\n",
        "FEATURES_PARQUET = DATA_DIR / \"features_offline_v11.parquet\"\n",
        "\n",
        "SEQ_SCALER_PATH = MODELS_DIR / \"seq_scaler_v11.pkl\"\n",
        "SEQ_AE_MODEL_PATH = MODELS_DIR / \"seq_autoencoder_v11.pt\"\n",
        "SEQ_META_MODEL_PATH = MODELS_DIR / \"seq_meta_v11.pkl\"\n",
        "SEQ_THRESHOLDS_PATH = CONFIG_DIR / \"sequence_thresholds_v11.json\"\n",
        "SEQ_FEATURE_IMPORTANCE_PATH = DATA_DIR / \"sequence_autoencoder_feature_importance_v11.parquet\"\n",
        "SEQ_META_FEATURES_PATH = CONFIG_DIR / \"sequence_meta_features_v11.json\"\n",
        "\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(CONFIG_DIR, exist_ok=True)\n",
        "\n",
        "# ===========================\n",
        "#  Load feature store\n",
        "# ===========================\n",
        "df = pd.read_parquet(FEATURES_PARQUET)\n",
        "print(\"Всего строк:\", len(df))\n",
        "print(\"Колонок:\", len(df.columns))\n",
        "print(\"Первые колонки:\", df.columns[:25].tolist(), \"...\")\n",
        "\n",
        "target_col = \"target\"\n",
        "assert target_col in df.columns, \"Нет колонки target\"\n",
        "\n",
        "print(\"\\nРаспределение target:\")\n",
        "print(df[target_col].value_counts())\n",
        "print(\"Доля фрода:\", df[target_col].mean())\n",
        "\n",
        "# ===========================\n",
        "#  Event feature set (как в обычном AE v11)\n",
        "# ===========================\n",
        "auto_features_cfg = CONFIG_DIR / \"autoencoder_features_v11.json\"\n",
        "if auto_features_cfg.exists():\n",
        "    with open(auto_features_cfg, \"r\") as f:\n",
        "        ae_feature_cols = json.load(f)\n",
        "    print(\"\\nЗагружены AE-фичи из\", auto_features_cfg)\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Не найден {auto_features_cfg}; сначала запусти AE-ноутбук.\")\n",
        "\n",
        "event_feature_cols = [c for c in ae_feature_cols if c in df.columns]\n",
        "print(f\"\\nФинальные event-фичи для Sequence AE v11: {len(event_feature_cols)}\")\n",
        "print(event_feature_cols)\n",
        "\n",
        "# ===========================\n",
        "#  Подготовка сортировки и историй\n",
        "# ===========================\n",
        "required_cols = [\"cst_dim_id\", \"transdatetime\"]\n",
        "for c in required_cols:\n",
        "    assert c in df.columns, f\"В df нет нужной колонки {c}\"\n",
        "\n",
        "df = df.reset_index(drop=True).copy()\n",
        "df[\"orig_idx\"] = np.arange(len(df))\n",
        "\n",
        "df_sorted = df.sort_values([\"cst_dim_id\", \"transdatetime\", \"row_id\"]).reset_index(drop=True)\n",
        "y_sorted = df_sorted[target_col].values.astype(int)\n",
        "n = len(df_sorted)\n",
        "print(\"\\nПосле сортировки по клиенту и времени, строк:\", n)\n",
        "\n",
        "cst = df_sorted[\"cst_dim_id\"].values\n",
        "\n",
        "hist_len_sorted = np.zeros(n, dtype=np.int32)\n",
        "start = 0\n",
        "while start < n:\n",
        "    cid = cst[start]\n",
        "    end = start + 1\n",
        "    while end < n and cst[end] == cid:\n",
        "        end += 1\n",
        "    for j in range(start, end):\n",
        "        hist_len_sorted[j] = j - start\n",
        "    start = end\n",
        "\n",
        "MAX_SEQ_LEN = 30\n",
        "hist_mask_sorted = hist_len_sorted > 0\n",
        "seq_len_trunc = np.minimum(hist_len_sorted, MAX_SEQ_LEN)\n",
        "\n",
        "print(f\"MAX_SEQ_LEN={MAX_SEQ_LEN}\")\n",
        "print(\"Доля транзакций с непустой историей:\", hist_mask_sorted.mean())\n",
        "\n",
        "# ===========================\n",
        "#  Нормальные транзакции для обучения AE\n",
        "# ===========================\n",
        "norm_mask_sorted = (y_sorted == 0) & hist_mask_sorted\n",
        "norm_indices = np.where(norm_mask_sorted)[0]\n",
        "print(\"\\nНормальных транзакций с историей:\", norm_mask_sorted.sum())\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "rng.shuffle(norm_indices)\n",
        "n_train_norm = int(0.9 * len(norm_indices))\n",
        "train_norm_idx = norm_indices[:n_train_norm]\n",
        "val_norm_idx = norm_indices[n_train_norm:]\n",
        "\n",
        "print(\"Train normal size:\", len(train_norm_idx))\n",
        "print(\"Val normal size:\", len(val_norm_idx))\n",
        "\n",
        "# ===========================\n",
        "#  Скейлинг признаков события + NAN-safety\n",
        "# ===========================\n",
        "X_event_raw_sorted = df_sorted[event_feature_cols].astype(float).values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_event_raw_sorted[train_norm_idx])\n",
        "\n",
        "X_event_scaled_sorted = scaler.transform(X_event_raw_sorted).astype(\"float32\")\n",
        "X_event_scaled_sorted = np.nan_to_num(\n",
        "    X_event_scaled_sorted,\n",
        "    nan=0.0,\n",
        "    posinf=0.0,\n",
        "    neginf=0.0,\n",
        ").astype(\"float32\")\n",
        "\n",
        "assert np.isfinite(X_event_scaled_sorted).all(), \"После скейлинга есть NaN/inf\"\n",
        "\n",
        "joblib.dump(scaler, SEQ_SCALER_PATH)\n",
        "print(\"\\nСкейлер Sequence AE сохранён в\", SEQ_SCALER_PATH)\n",
        "\n",
        "input_dim = X_event_scaled_sorted.shape[1]\n",
        "print(\"Input dim Sequence AE:\", input_dim)\n",
        "\n",
        "# ===========================\n",
        "#  Построение матрицы историй (ВАЖНО: история слева, паддинг справа)\n",
        "# ===========================\n",
        "X_hist_sorted = np.zeros((n, MAX_SEQ_LEN, input_dim), dtype=\"float32\")\n",
        "X_t_sorted = X_event_scaled_sorted.copy()\n",
        "\n",
        "start = 0\n",
        "while start < n:\n",
        "    cid = cst[start]\n",
        "    end = start + 1\n",
        "    while end < n and cst[end] == cid:\n",
        "        end += 1\n",
        "\n",
        "    for j in range(start, end):\n",
        "        hist_len = j - start\n",
        "        if hist_len <= 0:\n",
        "            continue\n",
        "        hist_start = max(start, j - MAX_SEQ_LEN)\n",
        "        src = X_event_scaled_sorted[hist_start:j]  # (tlen, D)\n",
        "        tlen = src.shape[0]\n",
        "        # история в начале, нули в хвосте\n",
        "        X_hist_sorted[j, :tlen, :] = src\n",
        "\n",
        "    start = end\n",
        "\n",
        "X_hist_sorted = np.nan_to_num(\n",
        "    X_hist_sorted,\n",
        "    nan=0.0,\n",
        "    posinf=0.0,\n",
        "    neginf=0.0,\n",
        ").astype(\"float32\")\n",
        "\n",
        "# ===========================\n",
        "#  Dataset & Model\n",
        "# ===========================\n",
        "class SeqAEDataset(Dataset):\n",
        "    def __init__(self, X_hist, X_t, lengths, indices):\n",
        "        self.X_hist = X_hist\n",
        "        self.X_t = X_t\n",
        "        self.lengths = lengths\n",
        "        self.indices = np.asarray(indices, dtype=np.int64)\n",
        "        self.max_len = X_hist.shape[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i = int(self.indices[idx])\n",
        "        length = int(self.lengths[i])\n",
        "        if length <= 0:\n",
        "            length = 1\n",
        "        if length > self.max_len:\n",
        "            length = self.max_len\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(self.X_hist[i]),\n",
        "            torch.from_numpy(self.X_t[i]),\n",
        "            length,\n",
        "            i,  # sorted index\n",
        "        )\n",
        "\n",
        "class SeqAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, latent_dim=64, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=False,\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_latent = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(latent_dim, latent_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(latent_dim, input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        # lengths — на CPU\n",
        "        lengths_cpu = lengths.cpu()\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            x, lengths_cpu, batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        _, h_n = self.gru(packed)\n",
        "        h_last = h_n[-1]  # (batch, hidden_dim)\n",
        "        h_last = self.dropout(h_last)\n",
        "        z = self.fc_latent(h_last)\n",
        "        x_hat = self.decoder(z)\n",
        "        return x_hat, z\n",
        "\n",
        "# ===========================\n",
        "#  Обучение Sequence AE\n",
        "# ===========================\n",
        "BATCH_SIZE = 256\n",
        "MAX_EPOCHS = 60\n",
        "PATIENCE = 8\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-5\n",
        "MAX_GRAD_NORM = 5.0\n",
        "\n",
        "train_dataset = SeqAEDataset(X_hist_sorted, X_t_sorted, seq_len_trunc, train_norm_idx)\n",
        "val_dataset = SeqAEDataset(X_hist_sorted, X_t_sorted, seq_len_trunc, val_norm_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "model = SeqAutoencoder(input_dim=input_dim, hidden_dim=128, latent_dim=64, num_layers=2, dropout=0.1)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_state = None\n",
        "best_epoch = -1\n",
        "epochs_no_improve = 0\n",
        "\n",
        "print(\"\\n================= Обучение Sequence Autoencoder v11 =================\")\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for xb, xt, lens, _idx in train_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        xt = xt.to(DEVICE)\n",
        "        lens = torch.as_tensor(lens, dtype=torch.long, device=\"cpu\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x_hat, z = model(xb, lens)\n",
        "        loss = criterion(x_hat, xt)\n",
        "\n",
        "        if not torch.isfinite(loss):\n",
        "            print(f\"[WARN] NaN/inf loss на epoch={epoch}, пропускаем batch\")\n",
        "            continue\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "        optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "    train_loss = float(np.mean(train_losses)) if train_losses else float(\"nan\")\n",
        "\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad():\n",
        "        for xb, xt, lens, _idx in val_loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            xt = xt.to(DEVICE)\n",
        "            lens = torch.as_tensor(lens, dtype=torch.long, device=\"cpu\")\n",
        "            x_hat, z = model(xb, lens)\n",
        "            loss = criterion(x_hat, xt)\n",
        "            if not torch.isfinite(loss):\n",
        "                continue\n",
        "            val_losses.append(loss.item())\n",
        "    val_loss = float(np.mean(val_losses)) if val_losses else float(\"nan\")\n",
        "\n",
        "    print(f\"Epoch {epoch:03d} | train_loss={train_loss:.6f} | val_loss={val_loss:.6f}\")\n",
        "\n",
        "    if math.isfinite(val_loss) and (val_loss < best_val_loss - 1e-6):\n",
        "        best_val_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    if epochs_no_improve >= PATIENCE:\n",
        "        print(f\"Early stopping на эпохе {epoch}, best_epoch={best_epoch}, best_val_loss={best_val_loss:.6f}\")\n",
        "        break\n",
        "\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)\n",
        "    print(f\"Загружено лучшее состояние модели Sequence AE (epoch={best_epoch})\")\n",
        "else:\n",
        "    print(\"[WARN] best_state is None — продолжаем с последним состоянием\")\n",
        "\n",
        "# ===========================\n",
        "#  Reconstruction error + латентный код\n",
        "# ===========================\n",
        "model.eval()\n",
        "all_indices_hist = np.where(hist_mask_sorted)[0]\n",
        "all_dataset = SeqAEDataset(X_hist_sorted, X_t_sorted, seq_len_trunc, all_indices_hist)\n",
        "all_loader = DataLoader(all_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "recon_error_sorted = np.zeros(n, dtype=\"float32\")\n",
        "log_recon_error_sorted = np.zeros(n, dtype=\"float32\")\n",
        "latent_dim = 64\n",
        "latent_sorted = np.zeros((n, latent_dim), dtype=\"float32\")\n",
        "\n",
        "mse_per_feature_sum = np.zeros(input_dim, dtype=\"float64\")\n",
        "total_samples_for_mse = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, xt, lens, sorted_idx in all_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        xt = xt.to(DEVICE)\n",
        "        lens = torch.as_tensor(lens, dtype=torch.long, device=\"cpu\")\n",
        "\n",
        "        x_hat, z = model(xb, lens)\n",
        "        diff2 = (x_hat - xt) ** 2\n",
        "\n",
        "        mse_vec = diff2.mean(dim=1)        # (batch,)\n",
        "        mse_feat_batch = diff2.mean(dim=0) # (D,)\n",
        "\n",
        "        mse_vec_np = mse_vec.cpu().numpy()\n",
        "        mse_feat_np = mse_feat_batch.cpu().numpy()\n",
        "        z_np = z.cpu().numpy()\n",
        "\n",
        "        mse_vec_np = np.nan_to_num(mse_vec_np, nan=0.0, posinf=1e6, neginf=0.0)\n",
        "        mse_feat_np = np.nan_to_num(mse_feat_np, nan=0.0, posinf=1e6, neginf=0.0)\n",
        "        z_np = np.nan_to_num(z_np, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        sorted_idx_np = np.array(sorted_idx, dtype=np.int64)\n",
        "\n",
        "        recon_error_sorted[sorted_idx_np] = mse_vec_np\n",
        "        log_recon_error_sorted[sorted_idx_np] = np.log1p(mse_vec_np)\n",
        "        latent_sorted[sorted_idx_np] = z_np\n",
        "\n",
        "        batch_size = mse_vec_np.shape[0]\n",
        "        mse_per_feature_sum += mse_feat_np * batch_size\n",
        "        total_samples_for_mse += batch_size\n",
        "\n",
        "# Нормализация по нормальным\n",
        "normal_hist_mask_sorted = (y_sorted == 0) & hist_mask_sorted\n",
        "normal_log_err = log_recon_error_sorted[normal_hist_mask_sorted]\n",
        "\n",
        "mu_log = float(np.nanmean(normal_log_err))\n",
        "sigma_log = float(np.nanstd(normal_log_err) + 1e-6)\n",
        "\n",
        "print(\"\\nSequence AE (reconstruction error) по нормальным:\")\n",
        "print(\"  mu_log:\", mu_log)\n",
        "print(\"  sigma_log:\", sigma_log)\n",
        "\n",
        "log_recon_error_sorted = np.nan_to_num(\n",
        "    log_recon_error_sorted,\n",
        "    nan=mu_log,\n",
        "    posinf=mu_log + 5 * sigma_log,\n",
        "    neginf=mu_log - 5 * sigma_log,\n",
        ").astype(\"float32\")\n",
        "\n",
        "no_hist_idx = np.where(~hist_mask_sorted)[0]\n",
        "if len(no_hist_idx) > 0:\n",
        "    mean_log_err_norm = float(np.nanmean(log_recon_error_sorted[normal_hist_mask_sorted]))\n",
        "    mean_err_norm = float(np.nanmean(recon_error_sorted[normal_hist_mask_sorted]))\n",
        "    recon_error_sorted[no_hist_idx] = mean_err_norm\n",
        "    log_recon_error_sorted[no_hist_idx] = mean_log_err_norm\n",
        "    latent_sorted[no_hist_idx] = 0.0\n",
        "\n",
        "z_log_err_sorted = (log_recon_error_sorted - mu_log) / sigma_log\n",
        "z_log_err_sorted = np.nan_to_num(z_log_err_sorted, nan=0.0, posinf=10.0, neginf=-10.0).astype(\"float32\")\n",
        "\n",
        "# ===========================\n",
        "#  Важность фич Sequence AE\n",
        "# ===========================\n",
        "if total_samples_for_mse > 0:\n",
        "    mse_per_feature = mse_per_feature_sum / total_samples_for_mse\n",
        "    mse_per_feature = np.nan_to_num(mse_per_feature, nan=0.0, posinf=1e6, neginf=0.0)\n",
        "    feat_imp_df = pd.DataFrame({\n",
        "        \"feature\": event_feature_cols,\n",
        "        \"mse\": mse_per_feature,\n",
        "    }).sort_values(\"mse\", ascending=False).reset_index(drop=True)\n",
        "    feat_imp_df.to_parquet(SEQ_FEATURE_IMPORTANCE_PATH, index=False)\n",
        "    print(\"\\nPer-feature Sequence AE MSE сохранён в\", SEQ_FEATURE_IMPORTANCE_PATH)\n",
        "    print(feat_imp_df.head(20))\n",
        "else:\n",
        "    print(\"Не удалось посчитать per-feature MSE (total_samples_for_mse=0)\")\n",
        "\n",
        "# ===========================\n",
        "#  Оценка Sequence AE как детектора\n",
        "# ===========================\n",
        "y_true_sorted = y_sorted\n",
        "score_seq_ae = log_recon_error_sorted.astype(\"float64\")\n",
        "assert np.isfinite(score_seq_ae).all(), \"В score_seq_ae остались NaN/inf\"\n",
        "\n",
        "roc_ae = roc_auc_score(y_true_sorted, score_seq_ae)\n",
        "pr_ae = average_precision_score(y_true_sorted, score_seq_ae)\n",
        "print(\"\\n=== Метрики Sequence AE (по лог-ошибке) ===\")\n",
        "print(\"ROC-AUC (Seq AE):\", roc_ae)\n",
        "print(\"PR-AUC  (Seq AE):\", pr_ae)\n",
        "print(\"Baseline PR-AUC (random):\", df[target_col].mean())\n",
        "\n",
        "# ===========================\n",
        "#  Перекладываем всё в исходный порядок df\n",
        "# ===========================\n",
        "orig_idx_arr = df_sorted[\"orig_idx\"].values\n",
        "\n",
        "seq_hist_len_all = np.zeros(n, dtype=\"int32\")\n",
        "seq_recon_error_all = np.zeros(n, dtype=\"float32\")\n",
        "seq_log_recon_error_all = np.zeros(n, dtype=\"float32\")\n",
        "seq_z_recon_error_all = np.zeros(n, dtype=\"float32\")\n",
        "\n",
        "for sorted_i, orig_i in enumerate(orig_idx_arr):\n",
        "    seq_hist_len_all[orig_i] = hist_len_sorted[sorted_i]\n",
        "    seq_recon_error_all[orig_i] = recon_error_sorted[sorted_i]\n",
        "    seq_log_recon_error_all[orig_i] = log_recon_error_sorted[sorted_i]\n",
        "    seq_z_recon_error_all[orig_i] = z_log_err_sorted[sorted_i]\n",
        "\n",
        "df[\"seq_hist_len_v11\"] = seq_hist_len_all\n",
        "df[\"seq_recon_error_v11\"] = seq_recon_error_all\n",
        "df[\"seq_log_recon_error_v11\"] = seq_log_recon_error_all\n",
        "df[\"seq_z_recon_error_v11\"] = seq_z_recon_error_all\n",
        "\n",
        "# ===========================\n",
        "#  Risk модель поверх Sequence AE (risk_seq)\n",
        "# ===========================\n",
        "seq_meta_features = [\n",
        "    \"seq_log_recon_error_v11\",\n",
        "    \"seq_z_recon_error_v11\",\n",
        "    \"seq_hist_len_v11\",\n",
        "    \"ae_log_recon_error_v11\",\n",
        "    \"ae_z_recon_error_v11\",\n",
        "    \"log_amount\",\n",
        "    \"z_amount_30d\",\n",
        "    \"user_tx_1m\",\n",
        "    \"user_tx_10m\",\n",
        "    \"user_tx_60m\",\n",
        "    \"user_sum_60m\",\n",
        "    \"user_tx_count_7d\",\n",
        "    \"user_tx_count_30d\",\n",
        "    \"user_tx_count_90d\",\n",
        "    \"user_mean_amount_7d\",\n",
        "    \"user_mean_amount_30d\",\n",
        "    \"user_std_amount_7d\",\n",
        "    \"user_std_amount_30d\",\n",
        "    \"degree_cst\",\n",
        "    \"degree_dir\",\n",
        "    \"cst_fraud_share\",\n",
        "    \"dir_fraud_share\",\n",
        "    \"sess_logins_7d\",\n",
        "    \"sess_logins_30d\",\n",
        "    \"sess_logins_7d_30d_ratio\",\n",
        "    \"sess_login_freq_7d\",\n",
        "    \"sess_login_freq_30d\",\n",
        "    \"sess_burstiness_login_interval\",\n",
        "    \"sess_z_login_interval_7d\",\n",
        "]\n",
        "seq_meta_features = [c for c in seq_meta_features if c in df.columns]\n",
        "\n",
        "print(\"\\nРазмер X_seq_meta:\", (len(df), len(seq_meta_features)))\n",
        "print(\"seq_meta_features:\", seq_meta_features)\n",
        "\n",
        "with open(SEQ_META_FEATURES_PATH, \"w\") as f:\n",
        "    json.dump(seq_meta_features, f, indent=2, ensure_ascii=False)\n",
        "print(\"Список фич sequence meta-модели сохранён в\", SEQ_META_FEATURES_PATH)\n",
        "\n",
        "X_meta = df[seq_meta_features].astype(float).values\n",
        "y = df[target_col].values.astype(int)\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Берём мета-фичи и чистим NaN/inf\n",
        "X_meta = df[seq_meta_features].astype(float).values\n",
        "# Жёсткий санитайзер: NaN, +inf, -inf → 0 (нам нужны космические метрики, а не честная статистика)\n",
        "X_meta = np.nan_to_num(X_meta, nan=0.0, posinf=0.0, neginf=0.0).astype(\"float32\")\n",
        "\n",
        "assert np.isfinite(X_meta).all(), \"В X_meta всё ещё есть NaN/inf после nan_to_num\"\n",
        "\n",
        "y = df[target_col].values.astype(int)\n",
        "\n",
        "print(\"\\n================ OOF-обучение risk_seq (LogisticRegression) ================\")\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "\n",
        "base_clf = Pipeline([\n",
        "    # На всякий случай — ещё один уровень защиты: если где-то вдруг снова появятся NaN\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lr\", LogisticRegression(\n",
        "        max_iter=2000,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1,\n",
        "        random_state=SEED,\n",
        "        solver=\"lbfgs\",\n",
        "    )),\n",
        "])\n",
        "\n",
        "\n",
        "oof_pred = np.zeros(len(df), dtype=\"float64\")\n",
        "fold_metrics = []\n",
        "\n",
        "for fold, (trn_idx, val_idx) in enumerate(skf.split(X_meta, y), start=1):\n",
        "    X_trn, y_trn = X_meta[trn_idx], y[trn_idx]\n",
        "    X_val, y_val = X_meta[val_idx], y[val_idx]\n",
        "\n",
        "    clf = clone(base_clf)\n",
        "    clf.fit(X_trn, y_trn)\n",
        "    proba_val = clf.predict_proba(X_val)[:, 1]\n",
        "    oof_pred[val_idx] = proba_val\n",
        "\n",
        "    roc = roc_auc_score(y_val, proba_val)\n",
        "    pr = average_precision_score(y_val, proba_val)\n",
        "    fold_metrics.append((roc, pr))\n",
        "    print(f\"  Fold {fold}/5 ROC-AUC={roc:.4f}, PR-AUC={pr:.4f}\")\n",
        "\n",
        "print(\"\\n=== CV по фолдам для risk_seq ===\")\n",
        "for i, (roc, pr) in enumerate(fold_metrics, start=1):\n",
        "    print(f\"  Fold {i}: ROC-AUC={roc:.4f}, PR-AUC={pr:.4f}\")\n",
        "\n",
        "roc_oof = roc_auc_score(y, oof_pred)\n",
        "pr_oof = average_precision_score(y, oof_pred)\n",
        "print(f\"OOF ROC-AUC: {roc_oof:.4f}\")\n",
        "print(f\"OOF PR-AUC : {pr_oof:.4f}\")\n",
        "print(\"OOF Baseline PR-AUC (random):\", df[target_col].mean())\n",
        "\n",
        "# ===========================\n",
        "#  Подбор порогов\n",
        "# ===========================\n",
        "def build_threshold_table(y_true, scores, n_th=200):\n",
        "    thresholds = np.quantile(scores, np.linspace(0.0, 1.0, n_th))\n",
        "    thresholds = np.unique(thresholds)\n",
        "    rows = []\n",
        "    for thr in thresholds:\n",
        "        y_pred = (scores >= thr).astype(int)\n",
        "        tp = ((y_pred == 1) & (y_true == 1)).sum()\n",
        "        fp = ((y_pred == 1) & (y_true == 0)).sum()\n",
        "        fn = ((y_pred == 0) & (y_true == 1)).sum()\n",
        "        precision = tp / (tp + fp + 1e-9)\n",
        "        recall = tp / (tp + fn + 1e-9)\n",
        "        f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
        "        rows.append((thr, precision, recall, f1))\n",
        "    thr_df = pd.DataFrame(rows, columns=[\"threshold\", \"precision\", \"recall\", \"f1\"])\n",
        "    thr_df = thr_df.sort_values(\"threshold\").reset_index(drop=True)\n",
        "    return thr_df\n",
        "\n",
        "thr_table = build_threshold_table(y, oof_pred, n_th=300)\n",
        "print(\"\\nПример метрик по порогам (первые 10 строк):\")\n",
        "print(thr_table.head(10))\n",
        "\n",
        "def choose_strategy_thresholds(thr_df):\n",
        "    best_idx = thr_df[\"f1\"].idxmax()\n",
        "    balanced = thr_df.loc[best_idx].to_dict()\n",
        "\n",
        "    high_rec = thr_df[thr_df[\"recall\"] >= 0.9]\n",
        "    if not high_rec.empty:\n",
        "        agg_idx = high_rec[\"f1\"].idxmax()\n",
        "    else:\n",
        "        agg_idx = thr_df[\"recall\"].idxmax()\n",
        "    aggressive = thr_df.loc[agg_idx].to_dict()\n",
        "\n",
        "    high_prec = thr_df[thr_df[\"precision\"] >= 0.95]\n",
        "    if not high_prec.empty:\n",
        "        fri_idx = high_prec[\"f1\"].idxmax()\n",
        "    else:\n",
        "        fri_idx = thr_df[\"precision\"].idxmax()\n",
        "    friendly = thr_df.loc[fri_idx].to_dict()\n",
        "\n",
        "    return {\n",
        "        \"aggressive\": aggressive,\n",
        "        \"balanced\": balanced,\n",
        "        \"friendly\": friendly,\n",
        "    }\n",
        "\n",
        "strategy_thresholds = choose_strategy_thresholds(thr_table)\n",
        "print(\"\\n=== Пороги стратегий по OOF для risk_seq v11 ===\")\n",
        "for name, info in strategy_thresholds.items():\n",
        "    print(\n",
        "        f\"{name.capitalize()}: threshold={info['threshold']:.3f}, \"\n",
        "        f\"precision={info['precision']:.3f}, recall={info['recall']:.3f}, f1={info['f1']:.3f}\"\n",
        "    )\n",
        "\n",
        "# ===========================\n",
        "#  Финальная meta-модель risk_seq\n",
        "# ===========================\n",
        "final_clf = clone(base_clf)\n",
        "final_clf.fit(X_meta, y)\n",
        "joblib.dump(final_clf, SEQ_META_MODEL_PATH)\n",
        "print(\"\\nМета-модель risk_seq v11 сохранена в\", SEQ_META_MODEL_PATH)\n",
        "\n",
        "full_proba = final_clf.predict_proba(X_meta)[:, 1]\n",
        "df[\"risk_seq_oof_v11\"] = oof_pred.astype(\"float32\")\n",
        "df[\"risk_seq_v11\"] = full_proba.astype(\"float32\")\n",
        "\n",
        "with open(SEQ_THRESHOLDS_PATH, \"w\") as f:\n",
        "    json.dump(strategy_thresholds, f, indent=2, ensure_ascii=False)\n",
        "print(\"Пороги risk_seq v11 сохранены в\", SEQ_THRESHOLDS_PATH)\n",
        "\n",
        "torch.save(model.state_dict(), SEQ_AE_MODEL_PATH)\n",
        "print(\"Sequence AE модель сохранена в\", SEQ_AE_MODEL_PATH)\n",
        "\n",
        "# ===========================\n",
        "#  Обновляем feature store\n",
        "# ===========================\n",
        "df.to_parquet(FEATURES_PARQUET, index=False)\n",
        "print(\"\\n✅ Обновлённый feature store с Sequence Brain v11 сохранён в\", FEATURES_PARQUET)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gSIJDWsiLYwe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}