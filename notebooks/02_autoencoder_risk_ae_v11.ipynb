{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dWXtAMNVY98",
        "outputId": "25636657-110a-46d3-a32d-b175acc216a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n",
            "Пробуем прочитать Parquet: data/processed/features_offline_v11.parquet\n",
            "✅ Успешно прочитан как Parquet.\n",
            "Всего строк: 13113\n",
            "Колонок: 193\n",
            "Первые колонки: ['transdatetime', 'cst_dim_id', 'transdate', 'amount', 'docno', 'direction', 'target', 'row_id', 'sess_monthly_os_changes', 'sess_monthly_phone_model_changes', 'sess_logins_7d', 'sess_logins_30d', 'sess_login_freq_7d', 'sess_login_freq_30d', 'sess_freq_change_7d_vs_mean', 'sess_logins_7d_30d_ratio', 'sess_avg_login_interval_30d', 'sess_std_login_interval_30d', 'sess_var_login_interval_30d', 'sess_ewm_login_interval_7d', 'sess_burstiness_login_interval', 'sess_fano_login_interval', 'sess_z_login_interval_7d', 'sess_has_login_history', 'sess_last_phone_model'] ...\n",
            "\n",
            "Распределение target по всему датасету:\n",
            "target\n",
            "0    12948\n",
            "1      165\n",
            "Name: count, dtype: int64\n",
            "Доля фрода: 0.012582932967284374\n",
            "\n",
            "Размеры групп фич:\n",
            "  base_cols: 34\n",
            "  graph_cols: 6\n",
            "  sess_cols: 18\n",
            "  emb_cst_cols: 64\n",
            "  emb_dir_cols: 64\n",
            "\n",
            "Размерность варианта F_full_without_node2vec (без node2vec):\n",
            "  base + graph + session = 34 + 6 + 16 = 56\n",
            "\n",
            "Финальные фичи для Autoencoder (только числовые): 56\n",
            "['amount', 'cst_fraud_share', 'dayofweek', 'decimal_depth', 'degree_cst', 'degree_dir', 'dir_fraud_share', 'dir_tx_60m', 'dir_unique_senders_60m', 'dow_cos', 'dow_sin', 'hour', 'hour_cos', 'hour_sin', 'is_weekend', 'log_amount', 'many_to_one_flag', 'one_to_many_flag', 'risk_fast_oof_v11', 'sess_avg_login_interval_30d', 'sess_burstiness_login_interval', 'sess_ewm_login_interval_7d', 'sess_fano_login_interval', 'sess_freq_change_7d_vs_mean', 'sess_has_login_history', 'sess_login_freq_30d', 'sess_login_freq_7d', 'sess_logins_30d', 'sess_logins_7d', 'sess_logins_7d_30d_ratio', 'sess_monthly_os_changes', 'sess_monthly_phone_model_changes', 'sess_std_login_interval_30d', 'sess_var_login_interval_30d', 'sess_z_login_interval_7d', 'user_max_amount_30d', 'user_max_amount_7d', 'user_max_amount_90d', 'user_mean_amount_30d', 'user_mean_amount_7d', 'user_mean_amount_90d', 'user_min_amount_30d', 'user_min_amount_7d', 'user_min_amount_90d', 'user_new_dirs_60m', 'user_std_amount_30d', 'user_std_amount_7d', 'user_std_amount_90d', 'user_sum_60m', 'user_tx_10m', 'user_tx_1m', 'user_tx_60m', 'user_tx_count_30d', 'user_tx_count_7d', 'user_tx_count_90d', 'z_amount_30d']\n",
            "\n",
            "Схема фич Autoencoder сохранена в config/autoencoder_features_v11.json\n",
            "\n",
            "Размер X_all: (13113, 56)\n",
            "Размер X_clean (target=0): (12948, 56)\n",
            "Train normal shape: (11653, 56)\n",
            "Val normal shape: (1295, 56)\n",
            "\n",
            "Скейлер AE сохранён в models/tx_scaler_v11.pkl\n",
            "\n",
            "Input dim AE: 56\n",
            "\n",
            "================= Обучение Autoencoder =================\n",
            "Epoch 001 | train_loss=0.915568 | val_loss=0.658306\n",
            "Epoch 010 | train_loss=0.402573 | val_loss=0.257618\n",
            "Epoch 020 | train_loss=0.326462 | val_loss=0.203967\n",
            "Epoch 030 | train_loss=0.293141 | val_loss=0.187843\n",
            "Epoch 040 | train_loss=0.273482 | val_loss=0.169798\n",
            "Epoch 050 | train_loss=0.261874 | val_loss=0.166452\n",
            "Epoch 060 | train_loss=0.253328 | val_loss=0.158229\n",
            "Epoch 070 | train_loss=0.237321 | val_loss=0.154085\n",
            "Epoch 080 | train_loss=0.233918 | val_loss=0.149812\n",
            "Epoch 090 | train_loss=0.232704 | val_loss=0.145995\n",
            "Epoch 100 | train_loss=0.236730 | val_loss=0.147609\n",
            "Epoch 110 | train_loss=0.227284 | val_loss=0.145581\n",
            "Epoch 120 | train_loss=0.221186 | val_loss=0.134878\n",
            "Epoch 130 | train_loss=0.218675 | val_loss=0.140322\n",
            "Epoch 140 | train_loss=0.213511 | val_loss=0.130585\n",
            "Epoch 150 | train_loss=0.215767 | val_loss=0.133554\n",
            "Epoch 160 | train_loss=0.211386 | val_loss=0.130684\n",
            "Epoch 170 | train_loss=0.209906 | val_loss=0.129802\n",
            "Epoch 180 | train_loss=0.213368 | val_loss=0.128955\n",
            "Epoch 190 | train_loss=0.209719 | val_loss=0.130384\n",
            "Epoch 200 | train_loss=0.203782 | val_loss=0.124307\n",
            "Epoch 210 | train_loss=0.201197 | val_loss=0.121642\n",
            "Epoch 220 | train_loss=0.200659 | val_loss=0.124135\n",
            "Epoch 230 | train_loss=0.197044 | val_loss=0.121750\n",
            "Epoch 240 | train_loss=0.198903 | val_loss=0.117792\n",
            "Epoch 250 | train_loss=0.194737 | val_loss=0.118536\n",
            "Epoch 260 | train_loss=0.194214 | val_loss=0.119202\n",
            "Early stopping на эпохе 260, best_epoch=235, best_val_loss=0.114696\n",
            "Загружено лучшее состояние модели (epoch=235)\n",
            "\n",
            "AE-анализ (reconstruction error) по всему датасету:\n",
            "  mu_log (normal): 0.0983303\n",
            "  sigma_log (normal): 0.13054302\n",
            "\n",
            "Per-feature AE MSE сохранён в data/processed/autoencoder_feature_importance_v11.parquet\n",
            "                             feature       mse\n",
            "16                  many_to_one_flag  0.712014\n",
            "6                    dir_fraud_share  0.374077\n",
            "5                         degree_dir  0.364350\n",
            "3                      decimal_depth  0.290888\n",
            "41               user_min_amount_30d  0.268684\n",
            "30           sess_monthly_os_changes  0.244684\n",
            "31  sess_monthly_phone_model_changes  0.234114\n",
            "9                            dow_cos  0.231224\n",
            "43               user_min_amount_90d  0.217304\n",
            "18                 risk_fast_oof_v11  0.212751\n",
            "25               sess_login_freq_30d  0.210885\n",
            "0                             amount  0.209784\n",
            "42                user_min_amount_7d  0.209149\n",
            "15                        log_amount  0.207331\n",
            "20    sess_burstiness_login_interval  0.205509\n",
            "48                      user_sum_60m  0.204395\n",
            "12                          hour_cos  0.202978\n",
            "54                 user_tx_count_90d  0.202193\n",
            "53                  user_tx_count_7d  0.199403\n",
            "38              user_mean_amount_30d  0.194697\n",
            "\n",
            "=== Метрики AE (по лог-ошибке) ===\n",
            "ROC-AUC (AE): 0.7589851246477752\n",
            "PR-AUC  (AE): 0.18239090523274196\n",
            "Baseline PR-AUC (random): 0.012582932967284374\n",
            "\n",
            "Квантили лог-ошибки по нормальным:\n",
            "  99% quantile: 0.5607258\n",
            "  99.9% quantile: 1.4784728\n",
            "\n",
            "AE-модель сохранена в models/tx_autoencoder_v11.pt\n",
            "\n",
            "Размер X_meta: (13113, 25)\n",
            "ae_meta_features: ['ae_log_recon_error_v11', 'ae_z_recon_error_v11', 'amount', 'log_amount', 'z_amount_30d', 'user_tx_1m', 'user_tx_10m', 'user_tx_60m', 'user_sum_60m', 'degree_cst', 'degree_dir', 'cst_fraud_share', 'dir_fraud_share', 'one_to_many_flag', 'many_to_one_flag', 'sess_logins_7d', 'sess_logins_30d', 'sess_logins_7d_30d_ratio', 'sess_login_freq_7d', 'sess_login_freq_30d', 'sess_burstiness_login_interval', 'sess_z_login_interval_7d', 'hour', 'dayofweek', 'is_weekend']\n",
            "Список фич мета-модели сохранён в config/autoencoder_meta_features_v11.json\n",
            "\n",
            "================ OOF-обучение risk_ae (LogisticRegression) ================\n",
            "\n",
            "=== Fold 1/5 ===\n",
            "  fold pos=132, neg=10358\n",
            "  Fold ROC-AUC=0.8739, PR-AUC=0.3248\n",
            "\n",
            "=== Fold 2/5 ===\n",
            "  fold pos=132, neg=10358\n",
            "  Fold ROC-AUC=0.8937, PR-AUC=0.4512\n",
            "\n",
            "=== Fold 3/5 ===\n",
            "  fold pos=132, neg=10358\n",
            "  Fold ROC-AUC=0.8995, PR-AUC=0.3762\n",
            "\n",
            "=== Fold 4/5 ===\n",
            "  fold pos=132, neg=10359\n",
            "  Fold ROC-AUC=0.9337, PR-AUC=0.3785\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "  fold pos=132, neg=10359\n",
            "  Fold ROC-AUC=0.8782, PR-AUC=0.3909\n",
            "\n",
            "=== CV по фолдам для risk_ae ===\n",
            "  Fold 1: ROC-AUC=0.8739, PR-AUC=0.3248\n",
            "  Fold 2: ROC-AUC=0.8937, PR-AUC=0.4512\n",
            "  Fold 3: ROC-AUC=0.8995, PR-AUC=0.3762\n",
            "  Fold 4: ROC-AUC=0.9337, PR-AUC=0.3785\n",
            "  Fold 5: ROC-AUC=0.8782, PR-AUC=0.3909\n",
            "\n",
            "ROC-AUC (OOF): 0.8938\n",
            "PR-AUC  (OOF): 0.3800\n",
            "Baseline PR-AUC (random): 0.012583\n",
            "\n",
            "=== Пороги стратегий по OOF для risk_ae ===\n",
            "Balanced: threshold=0.990, precision=0.920, recall=0.279, f1=0.428\n",
            "Aggressive: threshold=0.216, precision=0.029, recall=0.952, f1=0.056\n",
            "Friendly: threshold=1.000, precision=1.000, recall=0.176, f1=0.299\n",
            "\n",
            "Мета-модель risk_ae сохранена в models/tx_autoencoder_meta_v11.pkl\n",
            "\n",
            "Пороги AE/risk_ae сохранены в config/autoencoder_thresholds_v11.json\n",
            "\n",
            "✅ Обновлённый feature store с AE и risk_ae сохранён в data/processed/features_offline_v11.parquet\n",
            "\n",
            "Готово: Autoencoder v11 + risk_ae_v11 построены и сохранены.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    precision_recall_fscore_support\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "torch.cuda.manual_seed_all(RANDOM_STATE)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"DEVICE: {DEVICE}\")\n",
        "\n",
        "ROOT = Path(\".\")\n",
        "DATA_ROOT = ROOT / \"data\"\n",
        "PROC_PATH = DATA_ROOT / \"processed\"\n",
        "MODELS_PATH = ROOT / \"models\"\n",
        "CONFIG_PATH = ROOT / \"config\"\n",
        "\n",
        "for p in [DATA_ROOT, PROC_PATH, MODELS_PATH, CONFIG_PATH]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "FEATURES_PARQUET = PROC_PATH / \"features_offline_v11.parquet\"\n",
        "\n",
        "print(f\"Пробуем прочитать Parquet: {FEATURES_PARQUET}\")\n",
        "df = pd.read_parquet(FEATURES_PARQUET)\n",
        "print(\"Успешно прочитан как Parquet.\")\n",
        "print(\"Всего строк:\", len(df))\n",
        "print(\"Колонок:\", df.shape[1])\n",
        "print(\"Первые колонки:\", list(df.columns[:25]), \"...\")\n",
        "\n",
        "print(\"\\nРаспределение target по всему датасету:\")\n",
        "print(df[\"target\"].value_counts())\n",
        "fraud_share = df[\"target\"].mean()\n",
        "print(\"Доля фрода:\", fraud_share)\n",
        "\n",
        "\n",
        "all_cols = df.columns.tolist()\n",
        "\n",
        "id_cols = [\n",
        "    \"transdatetime\",\n",
        "    \"transdate\",\n",
        "    \"cst_dim_id\",\n",
        "    \"docno\",\n",
        "    \"direction\",\n",
        "    \"row_id\"\n",
        "]\n",
        "\n",
        "sess_cols = [c for c in all_cols if c.startswith(\"sess_\")]\n",
        "emb_cst_cols = [c for c in all_cols if c.startswith(\"emb_cst_\")]\n",
        "emb_dir_cols = [c for c in all_cols if c.startswith(\"emb_dir_\")]\n",
        "\n",
        "graph_cols = [\n",
        "    \"degree_cst\",\n",
        "    \"degree_dir\",\n",
        "    \"cst_fraud_share\",\n",
        "    \"dir_fraud_share\",\n",
        "    \"one_to_many_flag\",\n",
        "    \"many_to_one_flag\",\n",
        "]\n",
        "\n",
        "excluded_from_base = (\n",
        "    set(id_cols)\n",
        "    | set(sess_cols)\n",
        "    | set(emb_cst_cols)\n",
        "    | set(emb_dir_cols)\n",
        "    | set(graph_cols)\n",
        "    | {\"target\"}\n",
        ")\n",
        "\n",
        "base_cols = [\n",
        "    c for c in all_cols\n",
        "    if c not in excluded_from_base\n",
        "]\n",
        "\n",
        "print(\"\\nРазмеры групп фич:\")\n",
        "print(\"  base_cols:\", len(base_cols))\n",
        "print(\"  graph_cols:\", len(graph_cols))\n",
        "print(\"  sess_cols:\", len(sess_cols))\n",
        "print(\"  emb_cst_cols:\", len(emb_cst_cols))\n",
        "print(\"  emb_dir_cols:\", len(emb_dir_cols))\n",
        "\n",
        "\n",
        "sess_numeric_cols = [\n",
        "    c for c in sess_cols\n",
        "    if df[c].dtype != \"object\"\n",
        "]\n",
        "\n",
        "ae_feature_cols = base_cols + graph_cols + sess_numeric_cols\n",
        "\n",
        "ae_feature_cols = [\n",
        "    c for c in ae_feature_cols\n",
        "    if c not in {\n",
        "        \"ae_recon_error_v11\",\n",
        "        \"ae_log_recon_error_v11\",\n",
        "        \"ae_z_recon_error_v11\",\n",
        "        \"ae_percentile_v11\",\n",
        "        \"risk_ae_oof_v11\",\n",
        "        \"risk_ae_v11\",\n",
        "        \"anomaly_score_emb\",\n",
        "        \"ae_percentile\",\n",
        "        \"risk_ae\"\n",
        "    }\n",
        "]\n",
        "\n",
        "ae_feature_cols = [\n",
        "    c for c in ae_feature_cols\n",
        "    if np.issubdtype(df[c].dtype, np.number)\n",
        "]\n",
        "\n",
        "ae_feature_cols = sorted(ae_feature_cols)\n",
        "\n",
        "print(\"\\nРазмерность варианта F_full_without_node2vec (без node2vec):\")\n",
        "print(\"  base + graph + session =\", len(base_cols), \"+\", len(graph_cols), \"+\", len(sess_numeric_cols),\n",
        "      \"=\", len(base_cols) + len(graph_cols) + len(sess_numeric_cols))\n",
        "\n",
        "print(\"\\nФинальные фичи для Autoencoder (только числовые):\", len(ae_feature_cols))\n",
        "print(ae_feature_cols)\n",
        "\n",
        "# Схема фич AE\n",
        "ae_features_config_path = CONFIG_PATH / \"autoencoder_features_v11.json\"\n",
        "with ae_features_config_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(ae_feature_cols, f, ensure_ascii=False, indent=2)\n",
        "print(f\"\\nСхема фич Autoencoder сохранена в {ae_features_config_path}\")\n",
        "\n",
        "\n",
        "df_ae = df[ae_feature_cols].copy()\n",
        "\n",
        "df_ae = df_ae.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "medians = df_ae.median(axis=0)\n",
        "df_ae = df_ae.fillna(medians)\n",
        "\n",
        "X_all = df_ae.values.astype(np.float32)\n",
        "y_all = df[\"target\"].values.astype(int)\n",
        "\n",
        "mask_clean = (y_all == 0)\n",
        "X_clean = X_all[mask_clean]\n",
        "\n",
        "print(\"\\nРазмер X_all:\", X_all.shape)\n",
        "print(\"Размер X_clean (target=0):\", X_clean.shape)\n",
        "\n",
        "X_train, X_val = train_test_split(\n",
        "    X_clean,\n",
        "    test_size=0.1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "print(\"Train normal shape:\", X_train.shape)\n",
        "print(\"Val normal shape:\", X_val.shape)\n",
        "\n",
        "scaler_ae = StandardScaler()\n",
        "scaler_ae.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler_ae.transform(X_train)\n",
        "X_val_scaled = scaler_ae.transform(X_val)\n",
        "X_all_scaled = scaler_ae.transform(X_all)\n",
        "\n",
        "scaler_path = MODELS_PATH / \"tx_scaler_v11.pkl\"\n",
        "joblib.dump(scaler_ae, scaler_path)\n",
        "print(f\"\\nСкейлер AE сохранён в {scaler_path}\")\n",
        "\n",
        "\n",
        "class TabDataset(Dataset):\n",
        "    def __init__(self, X: np.ndarray):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx]\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_ds = TabDataset(X_train_scaled)\n",
        "val_ds = TabDataset(X_val_scaled)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "\n",
        "input_dim = X_train_scaled.shape[1]\n",
        "print(\"\\nInput dim AE:\", input_dim)\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim: int):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return out\n",
        "\n",
        "model_ae = AutoEncoder(input_dim=input_dim).to(DEVICE)\n",
        "criterion = nn.MSELoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.Adam(model_ae.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "max_epochs = 300\n",
        "patience = 25\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "best_state_dict = None\n",
        "best_epoch = -1\n",
        "no_improve_epochs = 0\n",
        "\n",
        "print(\"\\n================= Обучение Autoencoder =================\")\n",
        "\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    model_ae.train()\n",
        "    train_loss_sum = 0.0\n",
        "    train_batches = 0\n",
        "\n",
        "    for xb in train_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        recon = model_ae(xb)\n",
        "        loss = criterion(recon, xb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_sum += loss.item()\n",
        "        train_batches += 1\n",
        "\n",
        "    train_loss = train_loss_sum / max(1, train_batches)\n",
        "\n",
        "    model_ae.eval()\n",
        "    val_loss_sum = 0.0\n",
        "    val_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for xb in val_loader:\n",
        "            xb = xb.to(DEVICE)\n",
        "            recon = model_ae(xb)\n",
        "            loss = criterion(recon, xb)\n",
        "            val_loss_sum += loss.item()\n",
        "            val_batches += 1\n",
        "\n",
        "    val_loss = val_loss_sum / max(1, val_batches)\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch:03d} | train_loss={train_loss:.6f} | val_loss={val_loss:.6f}\")\n",
        "\n",
        "    if val_loss < best_val_loss - 1e-6:\n",
        "        best_val_loss = val_loss\n",
        "        best_state_dict = deepcopy(model_ae.state_dict())\n",
        "        best_epoch = epoch\n",
        "        no_improve_epochs = 0\n",
        "    else:\n",
        "        no_improve_epochs += 1\n",
        "        if no_improve_epochs >= patience:\n",
        "            print(f\"Early stopping на эпохе {epoch}, best_epoch={best_epoch}, best_val_loss={best_val_loss:.6f}\")\n",
        "            break\n",
        "\n",
        "if best_state_dict is not None:\n",
        "    model_ae.load_state_dict(best_state_dict)\n",
        "    print(f\"Загружено лучшее состояние модели (epoch={best_epoch})\")\n",
        "else:\n",
        "    print(\"best_state_dict is None — проверь лоссы (но после NaN-фикса этого быть не должно).\")\n",
        "\n",
        "model_ae.eval()\n",
        "with torch.no_grad():\n",
        "    X_all_t = torch.from_numpy(X_all_scaled).float().to(DEVICE)\n",
        "    recon_all_t = model_ae(X_all_t)\n",
        "    sq_err_t = (X_all_t - recon_all_t) ** 2\n",
        "    mse_all_t = sq_err_t.mean(dim=1)\n",
        "\n",
        "    mse_all = mse_all_t.cpu().numpy()\n",
        "    sq_err = sq_err_t.cpu().numpy()  \n",
        "\n",
        "df[\"ae_recon_error_v11\"] = mse_all\n",
        "df[\"ae_log_recon_error_v11\"] = np.log1p(mse_all)\n",
        "\n",
        "# Z-score\n",
        "log_err_clean = df.loc[df[\"target\"] == 0, \"ae_log_recon_error_v11\"].values\n",
        "mu_log = np.nanmean(log_err_clean)\n",
        "sigma_log = np.nanstd(log_err_clean, ddof=1)\n",
        "if sigma_log == 0 or not np.isfinite(sigma_log):\n",
        "    sigma_log = 1.0\n",
        "\n",
        "df[\"ae_z_recon_error_v11\"] = (df[\"ae_log_recon_error_v11\"] - mu_log) / (sigma_log + 1e-6)\n",
        "\n",
        "df[\"ae_percentile_v11\"] = df[\"ae_log_recon_error_v11\"].rank(pct=True)\n",
        "\n",
        "print(\"\\nAE-анализ (reconstruction error) по всему датасету:\")\n",
        "print(\"  mu_log (normal):\", mu_log)\n",
        "print(\"  sigma_log (normal):\", sigma_log)\n",
        "\n",
        "feature_mse = sq_err.mean(axis=0)  # (n_features,)\n",
        "ae_importance_df = pd.DataFrame({\n",
        "    \"feature\": ae_feature_cols,\n",
        "    \"mse\": feature_mse\n",
        "}).sort_values(\"mse\", ascending=False)\n",
        "\n",
        "ae_importance_path = PROC_PATH / \"autoencoder_feature_importance_v11.parquet\"\n",
        "ae_importance_df.to_parquet(ae_importance_path, index=False)\n",
        "print(f\"\\nPer-feature AE MSE сохранён в {ae_importance_path}\")\n",
        "print(ae_importance_df.head(20))\n",
        "\n",
        "\n",
        "y_true = df[\"target\"].values.astype(int)\n",
        "score_ae = df[\"ae_log_recon_error_v11\"].values\n",
        "\n",
        "roc_ae = roc_auc_score(y_true, score_ae)\n",
        "pr_ae = average_precision_score(y_true, score_ae)\n",
        "print(\"\\n=== Метрики AE (по лог-ошибке) ===\")\n",
        "print(\"ROC-AUC (AE):\", roc_ae)\n",
        "print(\"PR-AUC  (AE):\", pr_ae)\n",
        "print(\"Baseline PR-AUC (random):\", fraud_share)\n",
        "\n",
        "q99 = np.quantile(df.loc[df[\"target\"] == 0, \"ae_log_recon_error_v11\"], 0.99)\n",
        "q999 = np.quantile(df.loc[df[\"target\"] == 0, \"ae_log_recon_error_v11\"], 0.999)\n",
        "\n",
        "print(\"\\nКвантили лог-ошибки по нормальным:\")\n",
        "print(\"  99% quantile:\", q99)\n",
        "print(\"  99.9% quantile:\", q999)\n",
        "\n",
        "\n",
        "ae_model_path = MODELS_PATH / \"tx_autoencoder_v11.pt\"\n",
        "torch.save(model_ae.state_dict(), ae_model_path)\n",
        "print(f\"\\nAE-модель сохранена в {ae_model_path}\")\n",
        "\n",
        "\n",
        "ae_meta_features = [\n",
        "    \"ae_log_recon_error_v11\",\n",
        "    \"ae_z_recon_error_v11\",\n",
        "    \"amount\",\n",
        "    \"log_amount\",\n",
        "    \"z_amount_30d\",\n",
        "    \"user_tx_1m\",\n",
        "    \"user_tx_10m\",\n",
        "    \"user_tx_60m\",\n",
        "    \"user_sum_60m\",\n",
        "    \"degree_cst\",\n",
        "    \"degree_dir\",\n",
        "    \"cst_fraud_share\",\n",
        "    \"dir_fraud_share\",\n",
        "    \"one_to_many_flag\",\n",
        "    \"many_to_one_flag\",\n",
        "    \"sess_logins_7d\",\n",
        "    \"sess_logins_30d\",\n",
        "    \"sess_logins_7d_30d_ratio\",\n",
        "    \"sess_login_freq_7d\",\n",
        "    \"sess_login_freq_30d\",\n",
        "    \"sess_burstiness_login_interval\",\n",
        "    \"sess_z_login_interval_7d\",\n",
        "    \"hour\",\n",
        "    \"dayofweek\",\n",
        "    \"is_weekend\",\n",
        "]\n",
        "\n",
        "missing_meta = [c for c in ae_meta_features if c not in df.columns]\n",
        "if missing_meta:\n",
        "    raise ValueError(f\"Отсутствуют фичи для ae_meta_features: {missing_meta}\")\n",
        "\n",
        "df_meta = df[ae_meta_features].copy()\n",
        "df_meta = df_meta.replace([np.inf, -np.inf], np.nan)\n",
        "meta_medians = df_meta.median(axis=0)\n",
        "df_meta = df_meta.fillna(meta_medians)\n",
        "\n",
        "X_meta = df_meta.values.astype(np.float32)\n",
        "y_meta = df[\"target\"].values.astype(int)\n",
        "\n",
        "print(\"\\nРазмер X_meta:\", X_meta.shape)\n",
        "print(\"ae_meta_features:\", ae_meta_features)\n",
        "\n",
        "ae_meta_features_path = CONFIG_PATH / \"autoencoder_meta_features_v11.json\"\n",
        "with ae_meta_features_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(ae_meta_features, f, ensure_ascii=False, indent=2)\n",
        "print(f\"Список фич мета-модели сохранён в {ae_meta_features_path}\")\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "oof_pred = np.zeros(len(df), dtype=np.float32)\n",
        "fold_metrics = []\n",
        "\n",
        "print(\"\\n================ OOF-обучение risk_ae (LogisticRegression) ================\")\n",
        "\n",
        "for fold, (tr_idx, val_idx) in enumerate(skf.split(X_meta, y_meta), start=1):\n",
        "    X_tr, y_tr = X_meta[tr_idx], y_meta[tr_idx]\n",
        "    X_val, y_val = X_meta[val_idx], y_meta[val_idx]\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"logreg\", LogisticRegression(\n",
        "            class_weight=\"balanced\",\n",
        "            C=0.5,\n",
        "            max_iter=2000,\n",
        "            solver=\"lbfgs\",\n",
        "            n_jobs=-1,\n",
        "        )),\n",
        "    ])\n",
        "\n",
        "    print(f\"\\n=== Fold {fold}/5 ===\")\n",
        "    print(f\"  fold pos={y_tr.sum()}, neg={len(y_tr) - y_tr.sum()}\")\n",
        "\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    val_proba = pipe.predict_proba(X_val)[:, 1]\n",
        "    oof_pred[val_idx] = val_proba\n",
        "\n",
        "    fold_roc = roc_auc_score(y_val, val_proba)\n",
        "    fold_pr = average_precision_score(y_val, val_proba)\n",
        "    fold_metrics.append((fold_roc, fold_pr))\n",
        "\n",
        "    print(f\"  Fold ROC-AUC={fold_roc:.4f}, PR-AUC={fold_pr:.4f}\")\n",
        "\n",
        "roc_oof = roc_auc_score(y_meta, oof_pred)\n",
        "pr_oof = average_precision_score(y_meta, oof_pred)\n",
        "\n",
        "print(\"\\n=== CV по фолдам для risk_ae ===\")\n",
        "for i, (r, p) in enumerate(fold_metrics, start=1):\n",
        "    print(f\"  Fold {i}: ROC-AUC={r:.4f}, PR-AUC={p:.4f}\")\n",
        "print(f\"\\nROC-AUC (OOF): {roc_oof:.4f}\")\n",
        "print(f\"PR-AUC  (OOF): {pr_oof:.4f}\")\n",
        "print(f\"Baseline PR-AUC (random): {fraud_share:.6f}\")\n",
        "\n",
        "df[\"risk_ae_oof_v11\"] = oof_pred\n",
        "\n",
        "\n",
        "def compute_best_thresholds(score, y_true):\n",
        "    thresholds = np.linspace(score.min(), score.max(), 200)\n",
        "\n",
        "    best_f1 = -1.0\n",
        "    best_thr = None\n",
        "    best_prec = 0.0\n",
        "    best_rec = 0.0\n",
        "\n",
        "    stats = []\n",
        "\n",
        "    for thr in thresholds:\n",
        "        pred = (score >= thr).astype(int)\n",
        "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "            y_true, pred, average=\"binary\", zero_division=0\n",
        "        )\n",
        "        stats.append((thr, prec, rec, f1))\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_thr = thr\n",
        "            best_prec = prec\n",
        "            best_rec = rec\n",
        "\n",
        "    \n",
        "    best_aggr = None\n",
        "    best_aggr_score = -1.0\n",
        "    for thr, prec, rec, f1 in stats:\n",
        "        if rec >= 0.95:\n",
        "            score_aggr = f1 + 0.1 * prec\n",
        "            if score_aggr > best_aggr_score:\n",
        "                best_aggr_score = score_aggr\n",
        "                best_aggr = (thr, prec, rec, f1)\n",
        "    if best_aggr is None:\n",
        "        best_aggr = max(stats, key=lambda x: x[2])\n",
        "\n",
        "    # Friendly\n",
        "    best_friendly = None\n",
        "    best_friend_score = -1.0\n",
        "    for thr, prec, rec, f1 in stats:\n",
        "        score_friend = prec + 0.1 * rec\n",
        "        if score_friend > best_friend_score:\n",
        "            best_friend_score = score_friend\n",
        "            best_friendly = (thr, prec, rec, f1)\n",
        "\n",
        "    thr_bal, p_bal, r_bal, f1_bal = best_thr, best_prec, best_rec, best_f1\n",
        "    thr_aggr, p_aggr, r_aggr, f_aggr = best_aggr\n",
        "    thr_friend, p_friend, r_friend, f_friend = best_friendly\n",
        "\n",
        "    return {\n",
        "        \"balanced\": {\n",
        "            \"threshold\": float(thr_bal),\n",
        "            \"precision\": float(p_bal),\n",
        "            \"recall\": float(r_bal),\n",
        "            \"f1\": float(f1_bal),\n",
        "        },\n",
        "        \"aggressive\": {\n",
        "            \"threshold\": float(thr_aggr),\n",
        "            \"precision\": float(p_aggr),\n",
        "            \"recall\": float(r_aggr),\n",
        "            \"f1\": float(f_aggr),\n",
        "        },\n",
        "        \"friendly\": {\n",
        "            \"threshold\": float(thr_friend),\n",
        "            \"precision\": float(p_friend),\n",
        "            \"recall\": float(r_friend),\n",
        "            \"f1\": float(f_friend),\n",
        "        },\n",
        "    }\n",
        "\n",
        "thr_info = compute_best_thresholds(oof_pred, y_meta)\n",
        "\n",
        "print(\"\\n=== Пороги стратегий по OOF для risk_ae ===\")\n",
        "for name, stat in thr_info.items():\n",
        "    print(\n",
        "        f\"{name.capitalize()}: \"\n",
        "        f\"threshold={stat['threshold']:.3f}, \"\n",
        "        f\"precision={stat['precision']:.3f}, \"\n",
        "        f\"recall={stat['recall']:.3f}, \"\n",
        "        f\"f1={stat['f1']:.3f}\"\n",
        "    )\n",
        "\n",
        "\n",
        "final_meta_pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"logreg\", LogisticRegression(\n",
        "        class_weight=\"balanced\",\n",
        "        C=0.5,\n",
        "        max_iter=2000,\n",
        "        solver=\"lbfgs\",\n",
        "        n_jobs=-1,\n",
        "    )),\n",
        "])\n",
        "final_meta_pipe.fit(X_meta, y_meta)\n",
        "risk_full = final_meta_pipe.predict_proba(X_meta)[:, 1]\n",
        "df[\"risk_ae_v11\"] = risk_full\n",
        "\n",
        "meta_model_path = MODELS_PATH / \"tx_autoencoder_meta_v11.pkl\"\n",
        "joblib.dump(final_meta_pipe, meta_model_path)\n",
        "print(f\"\\nМета-модель risk_ae сохранена в {meta_model_path}\")\n",
        "\n",
        "\n",
        "thresholds_config = {\n",
        "    \"anomaly_score\": {\n",
        "        \"log_error_q99\": float(q99),\n",
        "        \"log_error_q999\": float(q999),\n",
        "        \"mu_log_normal\": float(mu_log),\n",
        "        \"sigma_log_normal\": float(sigma_log),\n",
        "    },\n",
        "    \"risk_ae\": thr_info,\n",
        "    \"oof_metrics\": {\n",
        "        \"roc_auc\": float(roc_oof),\n",
        "        \"pr_auc\": float(pr_oof),\n",
        "        \"fraud_share\": float(fraud_share),\n",
        "    },\n",
        "    \"ae_metrics\": {\n",
        "        \"roc_auc\": float(roc_ae),\n",
        "        \"pr_auc\": float(pr_ae),\n",
        "    },\n",
        "}\n",
        "\n",
        "thr_config_path = CONFIG_PATH / \"autoencoder_thresholds_v11.json\"\n",
        "with thr_config_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(thresholds_config, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"\\nПороги AE/risk_ae сохранены в {thr_config_path}\")\n",
        "\n",
        "\n",
        "df.to_parquet(FEATURES_PARQUET, index=False)\n",
        "print(f\"\\n✅ Обновлённый feature store с AE и risk_ae сохранён в {FEATURES_PARQUET}\")\n",
        "\n",
        "print(\"\\nГотово: Autoencoder v11 + risk_ae_v11 построены и сохранены.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI1VEf82VwWl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
